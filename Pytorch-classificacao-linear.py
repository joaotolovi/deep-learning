# -*- coding: utf-8 -*-
"""Olá, este é o Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb

lista para tensor

# Torch
"""

import torch

lista = [[1,2,3],[4,5,6]]
ts = torch.Tensor(lista)
print(ts)

"""Array para tensor"""

import numpy
arr = numpy.random.rand(3,4)
tn = torch.from_numpy(arr)

print(arr)
print(tn)

ts1 = torch.ones(2,3)
ts2 = torch.zeros(2,3)
ts3 = torch.randn(3,3)
print(ts1)
print(ts2)
print(ts3)

"""Modificando tensor"""

ts3[0,0]=10
print(ts3)

"""Acessando fatia de tensor"""

print(ts3[0:2])

"""Todas as linhas da coluna 2"""

print(ts3[:,1])

"""Acessando elemento"""

print(ts3[1,2])

"""Tamanho do tensor"""

print(ts3.size())

"""Dimensão

"""

print(ts3.shape)

tns = torch.randn(2,2,3)
print(tns)
#redimensionar achatou para quatro linhas e tres colunas
tns = tns.view(4,3)
print(tns)

"""verificar se gpu ta disponivel"""

if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')
print(device)

tns = tns.to(device)

tns = torch.randn(9, 12)
tns1 = tns[0:5, 0:4]
tns2 = tns[5:, 4:]

resultado = torch.mm(tns1, tns2)

tns1 =torch.randn(7,7,3)
tns2 = tns1.view(-1,1) 
tns3 = torch.randn(147,1)
#print(tns1.size(), tns2.size())
#print(tns2+tns3)

"""# Classificação Linear

Equação de reta é ax+by+c
"""

import numpy as np 


def plotline(a,b,c):
  a = a
  b = b 
  c = c

  #ax + by + c = 0
  # y = (-ax -c)/b

  x= np.linspace(-2,4,50)
  y = (-a*x -c) / b
  plt.axvline(0,-1,1,color='k', linewidth=1)
  plt.axhline(0,-1,1,color='k', linewidth=1)
  plt.plot(x,y)

a = -1
b = 4 
c = 0.4
plotline(a,b,c)

"""Pegando pontos da reta

"""

p1 = (2,0.4)
p2 = (1,0.6)
p3 = (1,-0.4)
ret1 = a*p1[0] + b*p1[1] + c
ret2 = a*p2[0] + b*p2[1] + c
ret3 = a*p3[0] + b*p3[1] + c
plotline(a,b,c)
plt.plot(p1[0],p1[1], color='b', marker='o')
plt.plot(p2[0],p2[1], color='b', marker='o')
plt.plot(p3[0],p3[1], color='b', marker='o')

print("%.2f"%ret1)
print("%.2f"%ret2)
print("%.2f"%ret3)

"""Criar classificação linear"""

from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
import numpy as np 

np.random.seed(30)
X, Y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class =1)

print(X.shape, Y.shape)
# X são os pontos no espaço e Y são a classe de cada ponto
plt.scatter(X[:,0], X[:,1], marker='o', c=Y)
p=X[10]
plt.plot(p[0],p[1], marker='^', markersize=10)
print(Y[10])

def plotmodel(w1,w2,b):
  plt.scatter(X[:,0], X[:,1], marker='o', c=Y)

  #ax + by + c = 0
  # y = (-ax -c)/b

  x= np.linspace(-2,4,50)
  y = (-w1*x -b) / w2
  plt.axvline(0,-1,1,color='k', linewidth=1)
  plt.axhline(0,-1,1,color='k', linewidth=1)
  plt.plot(x,y)

w1 = 0
w2 = 2 
b = 0
plotmodel(w1,w2,b)
p=X[10]

def classifyer(ponto, w1, w2, b):
  ret = (w1*ponto[0] + w2*ponto[1] +b)
  if ret >0:return (1, 'yellow')
  else:return (0, 'bue')

p=X[10]
classe, cor = classifyer(p, w1,w2,b)
print(classe,cor)
print(Y[10])

acertos=0
for k in range(len(X)):
  catg, _= classifyer(X[k], w1,w2,b)
  if catg == Y[k]:acertos+=1

print('acurracia:{0}'.format(acertos/len(X)))

"""# criando camada linear com torch"""

from torch import nn
import torch

torch.manual_seed(42)
perceptron = nn.Linear(in_features=3, out_features=1)
print(perceptron)

print(perceptron.weight.data)
print(perceptron.bias.data)

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def plot3d(perceptron):
  w1,w2,w3 = perceptron.weight.data.numpy()[0]
  b = perceptron.bias.data.numpy()

  X1 = np.linspace(-1,1,10)
  X2 = np.linspace(-1,1,10)

  X1,X2 = np.meshgrid(X1,X2)
  
  X3 = (b - w1*X1 - w2*X2) / w3

  fig = plt.figure(figsize=(10,8))

  ax = fig.gca(projection='3d')
  ax.view_init(azim=180)

  surf = ax.plot_surface(X1, X2, X3, cmap= 'plasma')

  

plot3d(perceptron)

x=torch.Tensor([0,1,2])
y=perceptron(x)
plot3d(perceptron)
plt.plot([x[0]],[x[1]],[x[2]], marker='o')
print(y)

"""# função de ativação"""

import torch
from torch import nn

from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
import numpy as np 

np.random.seed(46)
X, Y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class =1)

def plotmodel(w1,w2,b):
  plt.scatter(X[:,0], X[:,1], marker='o', c=Y)

  #ax + by + c = 0
  # y = (-ax -c)/b

  x= np.linspace(-2,4,50)
  y = (-w1*x -b) / w2
  plt.axvline(0,-1,1,color='k', linewidth=1)
  plt.axhline(0,-1,1,color='k', linewidth=1)
  plt.plot(x,y)

w1 = 0
w2 = 2 
b = 0
plotmodel(w1,w2,b)

perceptron = nn.Linear(in_features=2, out_features=1)

sigmoid = nn.Sigmoid()



w1 = 5
w2 = 1 
b = 0.4

perceptron.weight = nn.Parameter(torch.Tensor([[w1,w2]]))
perceptron.bias= nn.Parameter(torch.Tensor([b]))

print(perceptron.weight.data)
print(perceptron.bias.data)

from torch.nn.modules import activation
colors=['r','g','b','gray']
plt.figure(figsize=(8,6))
plotmodel(w1,w2,b)
for k, idx in enumerate([17,21,43,66]):
  x=torch.Tensor(X[idx])
  ret=perceptron(x)
  act=sigmoid(ret)
  activation=nn.Tanh()
  hip=activation(ret)
  limiar = 0 if ret < 0 else 1

  label = 'ret: {:5.2f}'.format(ret.data.numpy()[0]) + 'limiar: {:4.2f}'.format(limiar) + 'limiar: {:5.2f}'.format(act.data.numpy()[0]) + 'Hiperbo: {:5.2f}'.format(hip.data.numpy()[0])

  plt.plot(x[0],x[1], color=colors[k], marker='o', label=label)

plt.legend()
plt.show()